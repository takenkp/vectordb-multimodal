"""
ì‘ì„±ì : kp
ì‘ì„±ì¼ : 2025-05-13
ëª©ì  : PDF, ìŒì„±, ì˜ìƒ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ í›„ Chroma DBì— ì—…ë¡œë“œ ë° ìœ ì‚¬ë„ ê²€ìƒ‰
ë‚´ìš© : OCR ë° STT í…ìŠ¤íŠ¸ë¥¼ 'ë‚´ìš©' í•„ë“œë¡œ ë²¡í„°í™”í•˜ì—¬ ì €ì¥ í›„, ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰ ìˆ˜í–‰
"""

import os
from pdf_processor import extract_text_and_images_from_pdf
from voice_processor import extract_text_from_voice, extract_info_from_voice
from video_processor import extract_text_from_video, extract_info_from_video
import re
import chromadb
from chromadb.utils import embedding_functions

# Chroma ì„¤ì •
client = chromadb.Client()
collection = client.get_or_create_collection(
    name="multimodal-documents",
    embedding_function=embedding_functions.SentenceTransformerEmbeddingFunction(model_name="all-MiniLM-L6-v2")
)

def process_file_and_upload(file_path):
    ext = os.path.splitext(file_path)[1].lower()
    file_name = os.path.basename(file_path)

    try:
        if ext == ".pdf":
            print(f"[INFO] PDF ì²˜ë¦¬ ì‹œì‘: {file_name}")
            paragraphs, images = extract_text_and_images_from_pdf(file_path)

            for i, para in enumerate(paragraphs):
                clean_text = para.strip()

                # â‘  ê¸¸ì´ í•„í„°ë§
                if len(clean_text) < 30:
                    continue

                # â‘¡ ì˜ë¯¸ ì—†ëŠ” ë°˜ë³µ ë¬¸ì í•„í„°ë§
                if re.match(r"^(k|ã…|\.|\s){3,}$", clean_text, re.IGNORECASE):
                    continue

                para_id = f"{file_path}#chunk_{i+1}"
                meta = {
                    "ìœ í˜•": "pdf",
                    "íŒŒì¼ëª…": file_name,
                    "ì²­í¬": i + 1
                }

                collection.add(
                    documents=[clean_text],
                    metadatas=[meta],
                    ids=[para_id]
                )
                print("clean_textëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤. ì´ëŠ” ì•„ë˜ ë‚´ì—­ì—ì„œ í™•ì¸ê°€ëŠ¥í•©ë‹ˆë‹¤.")
                print(clean_text)
                print(f"[UPLOAD] '{file_name}' â†’ ì²­í¬ {i+1} ì—…ë¡œë“œ ì™„ë£Œ")

        elif ext == ".mp3":
            print(f"[INFO] ìŒì„± ì²˜ë¦¬ ì‹œì‘: {file_name}")
            text = extract_text_from_voice(file_path)
            meta = {
                "ìœ í˜•": "voice",
                "íŒŒì¼ëª…": file_name,
                "ë‚´ìš©": extract_info_from_voice(file_path)
            }

        elif ext == ".mp4":
            print(f"[INFO] ì˜ìƒ ì²˜ë¦¬ ì‹œì‘: {file_name}")
            text = extract_text_from_video(file_path)
            meta = {
                "ìœ í˜•": "video",
                "íŒŒì¼ëª…": file_name,
                "ë‚´ìš©": extract_info_from_video(file_path)
            }

        else:
            print(f"[SKIP] ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_name}")
            return

        if not text or not text.strip():
            raise RuntimeError(f"[ERROR] í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {file_name}")

        collection.add(
            documents=[text],
            metadatas=[meta],
            ids=[file_path]
        )
        print(f"[UPLOAD] '{file_name}' â†’ ë²¡í„° DBì— ì—…ë¡œë“œ ì™„ë£Œ")

    except Exception as e:
        print(f"[FAIL] íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {file_name} - {e}")

def collect_files_from_directories(base_dirs):
    """ì§€ì •ëœ ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  ìœ íš¨ íŒŒì¼ ìˆ˜ì§‘"""
    valid_exts = {".pdf", ".mp3", ".mp4"}
    files = []

    for base_dir in base_dirs:
        for root, _, filenames in os.walk(base_dir):
            for fname in filenames:
                if os.path.splitext(fname)[1].lower() in valid_exts:
                    files.append(os.path.join(root, fname))
    return files

def search_similar_documents(query, top_k=5):
    """ì‚¬ìš©ì ì¿¼ë¦¬ë¡œ Chromaì—ì„œ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰"""
    print(f"\nğŸ” ê²€ìƒ‰ì–´: '{query}' â†’ ìœ ì‚¬ ë¬¸ì„œ {top_k}ê±´\n")

    results = collection.query(
        query_texts=[query],
        n_results=top_k
    )

    if not results['documents'] or not results['documents'][0]:
        print("âŒ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n")
        return

    for i, doc in enumerate(results['documents'][0]):
        distance = results['distances'][0][i]
        similarity = distance  # âœ… ìœ ì‚¬ë„ ìŒìˆ˜ ë°©ì§€

        metadata = results['metadatas'][0][i]
        doc_id = results['ids'][0][i]

        print(f"[{i+1}] ID: {doc_id}")
        print(f"    ìœ í˜•: {metadata.get('ìœ í˜•')}, íŒŒì¼ëª…: {metadata.get('íŒŒì¼ëª…')}")
        print(f"    ìœ ì‚¬ë„: {similarity:.4f} (ë†’ì„ìˆ˜ë¡ ìœ ì‚¬)")
        print(f"    ë‚´ìš©: {doc}...\n")


if __name__ == "__main__":
    # 1ë‹¨ê³„: íŒŒì¼ ìˆ˜ì§‘ ë° ì—…ë¡œë“œ
    target_dirs = ["./pdf", "./voice", "./video"]
    all_files = collect_files_from_directories(target_dirs)

    print(f"\nì´ {len(all_files)}ê°œ íŒŒì¼ ì²˜ë¦¬ ì‹œì‘...\n")
    for f in all_files:
        process_file_and_upload(f)

    # 2ë‹¨ê³„: ê²€ìƒ‰ ë£¨í”„
    print("\n==============================")
    print("âœ… ëª¨ë“  ë¬¸ì„œ ì—…ë¡œë“œ ì™„ë£Œ. ê²€ìƒ‰ ëª¨ë“œë¡œ ì§„ì…í•©ë‹ˆë‹¤.")
    print("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œí•˜ë ¤ë©´ 'exit'):")
    print("==============================\n")

    while True:
        query = input("ğŸ” ê²€ìƒ‰ì–´: ")
        if query.lower() == "exit":
            print("ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        search_similar_documents(query)
